{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jhonathan_at03.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ndffr2YGd2WX",
        "4NIf2Opve3tY"
      ],
      "authorship_tag": "ABX9TyNScaBonTNFjgykoSW/+LSr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jh0n3/at01/blob/master/Jhonathan_at03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9YrofCdcZ2Y",
        "colab_type": "text"
      },
      "source": [
        "## **Dados de Árvores emergentes na Amazônia Brasileira**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgqdZz84c8T8",
        "colab_type": "text"
      },
      "source": [
        "* Dataset contendo atributos oriundos de um Modelo Digital de Terreno (MDT) bem como a localização de árvores que se elevam além do dossel florestal, ditas árvores emergentes, na Amazônia brasileira.\n",
        "* Os atributos topográficos (numéricos) são:\n",
        " * Elevação (altitude) - DTM\n",
        " * Indice Topográfico de Umidade - TWI\n",
        " * Declividade - SLP\n",
        " * Aspecto (azimute da declividade) - ASP\n",
        " * Distância horizontal até o corpo dágua mais próximo - HDI\n",
        " * Distância vartical até o corpo dágua mais próximo - VDI\n",
        " * Índice de Roustez Topográfica - RGX\n",
        " * Índice de Posição Topográfica - TPI\n",
        " * Índice de Convergência Topográfica - TCI\n",
        " * Direção de Fluxo de água - DIR\n",
        " * Índice de Rugosidade Topográfica - TRI\n",
        "* 632 instâncias\n",
        "\n",
        "* O dataset está balanceado, pois existem 50% de ocorrenica de Arvores Emergentes (AE) e 50% de Arvores nãop Emergentes (ANE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yDviUnAdg_Z",
        "colab_type": "text"
      },
      "source": [
        "**Montando o ambiente no Google Drive**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeRTn6vjdik9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "77a5d6dd-5f57-46e9-9583-e2b296e9d42a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount = True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkLfe441dl-e",
        "colab_type": "text"
      },
      "source": [
        "## 1. Importar bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bli7fDLpdzYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando bibliotecas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndffr2YGd2WX",
        "colab_type": "text"
      },
      "source": [
        "## 2. Lendo os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6bQFjkId6Y-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "83eb3931-8b11-4e4f-c900-bc5cbb9fc251"
      },
      "source": [
        "# lendo csv e armazenando em um dataframe\n",
        "dados = pd.read_csv('/content/drive/My Drive/ML_jh0n3/emergentesP50_corrClean.csv')\n",
        "dados.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EMERGENTE</th>\n",
              "      <th>DTM</th>\n",
              "      <th>TWI</th>\n",
              "      <th>SLP</th>\n",
              "      <th>ASP</th>\n",
              "      <th>HDI</th>\n",
              "      <th>VDI</th>\n",
              "      <th>TPI</th>\n",
              "      <th>TCI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>52.877316</td>\n",
              "      <td>5.646127</td>\n",
              "      <td>1.115717</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>268.882263</td>\n",
              "      <td>0.858570</td>\n",
              "      <td>-0.005764</td>\n",
              "      <td>8.405160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>76.121002</td>\n",
              "      <td>0.458159</td>\n",
              "      <td>13.319283</td>\n",
              "      <td>196.762161</td>\n",
              "      <td>250.362488</td>\n",
              "      <td>27.497246</td>\n",
              "      <td>0.408562</td>\n",
              "      <td>-0.427912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>62.663570</td>\n",
              "      <td>5.795762</td>\n",
              "      <td>2.120610</td>\n",
              "      <td>208.456863</td>\n",
              "      <td>409.534058</td>\n",
              "      <td>3.184376</td>\n",
              "      <td>-0.008343</td>\n",
              "      <td>3.405835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>66.057808</td>\n",
              "      <td>2.950522</td>\n",
              "      <td>32.357330</td>\n",
              "      <td>327.166534</td>\n",
              "      <td>304.391907</td>\n",
              "      <td>16.927715</td>\n",
              "      <td>0.187172</td>\n",
              "      <td>2.162333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>69.429962</td>\n",
              "      <td>4.540288</td>\n",
              "      <td>24.646606</td>\n",
              "      <td>143.793945</td>\n",
              "      <td>99.468040</td>\n",
              "      <td>19.007271</td>\n",
              "      <td>-0.007156</td>\n",
              "      <td>3.556503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   EMERGENTE        DTM       TWI  ...        VDI       TPI       TCI\n",
              "0          0  52.877316  5.646127  ...   0.858570 -0.005764  8.405160\n",
              "1          0  76.121002  0.458159  ...  27.497246  0.408562 -0.427912\n",
              "2          0  62.663570  5.795762  ...   3.184376 -0.008343  3.405835\n",
              "3          0  66.057808  2.950522  ...  16.927715  0.187172  2.162333\n",
              "4          0  69.429962  4.540288  ...  19.007271 -0.007156  3.556503\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NIf2Opve3tY",
        "colab_type": "text"
      },
      "source": [
        "## 3. Limpeza e organização dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhtMFqsve9NI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#verificar se existem valores NAN, ? ou dados faltantes\n",
        "dados = dados.dropna()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q8ENFoDfa0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#excluir colunas irrelevantes\n",
        "#dados = dados.drop(columns=['RDM','RGX','DIR, 'TRI'])\n",
        "#dados.head()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twkFNp8_fzfJ",
        "colab_type": "text"
      },
      "source": [
        "## 4. Reescalonamento dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIBsNy7bf2pL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "68c36fea-ac94-42b7-f9a4-ba39aa4506d7"
      },
      "source": [
        "dados = (dados - dados.min())/(dados.max()-dados.min())\n",
        "dados.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EMERGENTE</th>\n",
              "      <th>DTM</th>\n",
              "      <th>TWI</th>\n",
              "      <th>SLP</th>\n",
              "      <th>ASP</th>\n",
              "      <th>HDI</th>\n",
              "      <th>VDI</th>\n",
              "      <th>TPI</th>\n",
              "      <th>TCI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091426</td>\n",
              "      <td>0.508997</td>\n",
              "      <td>0.020933</td>\n",
              "      <td>0.633415</td>\n",
              "      <td>0.258782</td>\n",
              "      <td>0.015793</td>\n",
              "      <td>0.398346</td>\n",
              "      <td>0.716769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>0.022587</td>\n",
              "      <td>0.249899</td>\n",
              "      <td>0.553921</td>\n",
              "      <td>0.240769</td>\n",
              "      <td>0.518095</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.059528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260921</td>\n",
              "      <td>0.523027</td>\n",
              "      <td>0.039787</td>\n",
              "      <td>0.586843</td>\n",
              "      <td>0.395590</td>\n",
              "      <td>0.059649</td>\n",
              "      <td>0.394601</td>\n",
              "      <td>0.344785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.319708</td>\n",
              "      <td>0.256264</td>\n",
              "      <td>0.607093</td>\n",
              "      <td>0.921032</td>\n",
              "      <td>0.293321</td>\n",
              "      <td>0.318795</td>\n",
              "      <td>0.678514</td>\n",
              "      <td>0.252260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.378113</td>\n",
              "      <td>0.405317</td>\n",
              "      <td>0.462424</td>\n",
              "      <td>0.404806</td>\n",
              "      <td>0.093998</td>\n",
              "      <td>0.358007</td>\n",
              "      <td>0.396324</td>\n",
              "      <td>0.355996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   EMERGENTE       DTM       TWI  ...       VDI       TPI       TCI\n",
              "0        0.0  0.091426  0.508997  ...  0.015793  0.398346  0.716769\n",
              "1        0.0  0.494000  0.022587  ...  0.518095  1.000000  0.059528\n",
              "2        0.0  0.260921  0.523027  ...  0.059649  0.394601  0.344785\n",
              "3        0.0  0.319708  0.256264  ...  0.318795  0.678514  0.252260\n",
              "4        0.0  0.378113  0.405317  ...  0.358007  0.396324  0.355996\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epQijZjxirlh",
        "colab_type": "text"
      },
      "source": [
        "## 5. Organizando dados para modelagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7qi5tHeit5j",
        "colab_type": "text"
      },
      "source": [
        "### Dividir os dados em atributos descritores e atributo de classe (target)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTp1_Qcsiyu6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "bf16f8e6-8f3b-497e-e252-6cba370c96f3"
      },
      "source": [
        "#dividindo dados em atributos descritores e atributo de classe\n",
        "X = dados.iloc[:,1:]\n",
        "X.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DTM</th>\n",
              "      <th>TWI</th>\n",
              "      <th>SLP</th>\n",
              "      <th>ASP</th>\n",
              "      <th>HDI</th>\n",
              "      <th>VDI</th>\n",
              "      <th>TPI</th>\n",
              "      <th>TCI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.091426</td>\n",
              "      <td>0.508997</td>\n",
              "      <td>0.020933</td>\n",
              "      <td>0.633415</td>\n",
              "      <td>0.258782</td>\n",
              "      <td>0.015793</td>\n",
              "      <td>0.398346</td>\n",
              "      <td>0.716769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.494000</td>\n",
              "      <td>0.022587</td>\n",
              "      <td>0.249899</td>\n",
              "      <td>0.553921</td>\n",
              "      <td>0.240769</td>\n",
              "      <td>0.518095</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.059528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.260921</td>\n",
              "      <td>0.523027</td>\n",
              "      <td>0.039787</td>\n",
              "      <td>0.586843</td>\n",
              "      <td>0.395590</td>\n",
              "      <td>0.059649</td>\n",
              "      <td>0.394601</td>\n",
              "      <td>0.344785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.319708</td>\n",
              "      <td>0.256264</td>\n",
              "      <td>0.607093</td>\n",
              "      <td>0.921032</td>\n",
              "      <td>0.293321</td>\n",
              "      <td>0.318795</td>\n",
              "      <td>0.678514</td>\n",
              "      <td>0.252260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.378113</td>\n",
              "      <td>0.405317</td>\n",
              "      <td>0.462424</td>\n",
              "      <td>0.404806</td>\n",
              "      <td>0.093998</td>\n",
              "      <td>0.358007</td>\n",
              "      <td>0.396324</td>\n",
              "      <td>0.355996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        DTM       TWI       SLP  ...       VDI       TPI       TCI\n",
              "0  0.091426  0.508997  0.020933  ...  0.015793  0.398346  0.716769\n",
              "1  0.494000  0.022587  0.249899  ...  0.518095  1.000000  0.059528\n",
              "2  0.260921  0.523027  0.039787  ...  0.059649  0.394601  0.344785\n",
              "3  0.319708  0.256264  0.607093  ...  0.318795  0.678514  0.252260\n",
              "4  0.378113  0.405317  0.462424  ...  0.358007  0.396324  0.355996\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G93g0WzGi6M9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "33d8396d-87e8-470f-d692-3ad79d0c1677"
      },
      "source": [
        "y = dados.EMERGENTE\n",
        "y.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.0\n",
              "1    0.0\n",
              "2    0.0\n",
              "3    0.0\n",
              "4    0.0\n",
              "Name: EMERGENTE, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug7w9wuSjSNw",
        "colab_type": "text"
      },
      "source": [
        "### Dividir os dados em treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjoa8a4njTLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94xAlqD3j9-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6jPAXwnkWIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "95b774ef-f4f3-442b-cda9-bfbad11219e9"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DTM</th>\n",
              "      <th>TWI</th>\n",
              "      <th>SLP</th>\n",
              "      <th>ASP</th>\n",
              "      <th>HDI</th>\n",
              "      <th>VDI</th>\n",
              "      <th>TPI</th>\n",
              "      <th>TCI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.957024</td>\n",
              "      <td>0.366936</td>\n",
              "      <td>0.014473</td>\n",
              "      <td>0.412717</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.692389</td>\n",
              "      <td>0.411713</td>\n",
              "      <td>0.074315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>0.370007</td>\n",
              "      <td>0.340751</td>\n",
              "      <td>0.216376</td>\n",
              "      <td>0.473671</td>\n",
              "      <td>0.166960</td>\n",
              "      <td>0.407311</td>\n",
              "      <td>0.372859</td>\n",
              "      <td>0.216018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>0.987404</td>\n",
              "      <td>0.380633</td>\n",
              "      <td>0.024196</td>\n",
              "      <td>0.482971</td>\n",
              "      <td>0.672969</td>\n",
              "      <td>0.530025</td>\n",
              "      <td>0.429804</td>\n",
              "      <td>0.257896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>0.496951</td>\n",
              "      <td>0.505619</td>\n",
              "      <td>0.378548</td>\n",
              "      <td>0.352265</td>\n",
              "      <td>0.344246</td>\n",
              "      <td>0.447013</td>\n",
              "      <td>0.095034</td>\n",
              "      <td>0.819955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>0.491617</td>\n",
              "      <td>0.365815</td>\n",
              "      <td>0.196821</td>\n",
              "      <td>0.420027</td>\n",
              "      <td>0.252705</td>\n",
              "      <td>0.070667</td>\n",
              "      <td>0.400744</td>\n",
              "      <td>0.351838</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          DTM       TWI       SLP  ...       VDI       TPI       TCI\n",
              "6    0.957024  0.366936  0.014473  ...  0.692389  0.411713  0.074315\n",
              "104  0.370007  0.340751  0.216376  ...  0.407311  0.372859  0.216018\n",
              "114  0.987404  0.380633  0.024196  ...  0.530025  0.429804  0.257896\n",
              "493  0.496951  0.505619  0.378548  ...  0.447013  0.095034  0.819955\n",
              "414  0.491617  0.365815  0.196821  ...  0.070667  0.400744  0.351838\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK1ICB2jkyTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "56e66f34-369a-4b94-b110-9d1b608fde5c"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6      0.0\n",
              "104    0.0\n",
              "114    0.0\n",
              "493    1.0\n",
              "414    1.0\n",
              "Name: EMERGENTE, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LJacRqvlK77",
        "colab_type": "text"
      },
      "source": [
        "## 6. Definindo o algoritmo de aprendizagem (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7CoAmvMlUcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiNfhrzilcWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#definindo modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR83MovsldW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "34b58723-5cb7-4538-92e7-098b3015c834"
      },
      "source": [
        "#treinando modelo\n",
        "classificador.fit(X_train,y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
              "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgVTI43noci8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "8873ad42-ac8e-4b72-dca2-02a312c98f18"
      },
      "source": [
        "#realizando classificação\n",
        "classificacao = classificador.predict(X_test)\n",
        "classificacao"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 1., 0., 1., 0., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muhtAI3lJbNv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0sOilTpGgQb",
        "colab_type": "text"
      },
      "source": [
        "## Comentários:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP76bPVfKXPq",
        "colab_type": "text"
      },
      "source": [
        "## 7. Avaliação do classificador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD79Rr9tsqqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando acurácia\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9MY_5GdsulC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc02e27c-d435-4a90-97d7-d1cb0298c0c9"
      },
      "source": [
        "acuracia = accuracy_score(y_test,classificacao)\n",
        "round(acuracia,3)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.638"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6IE6MIlszlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando precisão\n",
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR2hlaPus5E2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "631d3307-6a15-49a7-9815-4c3caa1c6712"
      },
      "source": [
        "precisao = precision_score(y_test,classificacao)\n",
        "round(precisao,3)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaVRK5I5s8pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando recall (revocação)\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brwuxsT9s86R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f2ba93a-750e-473b-8df7-bf09ed22234b"
      },
      "source": [
        "recall = recall_score(y_test,classificacao)\n",
        "round(recall,3)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.63"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhrTy63HtMVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando f1-score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7zYn_9OtRMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54f02f25-3466-4d1c-bce2-82b1462c9b2b"
      },
      "source": [
        "f1 = f1_score(y_test,classificacao)\n",
        "round(f1,3)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKMx-LdwtpCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotando curva roc\n",
        "from sklearn.metrics  import roc_curve"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvW9puhqtq11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr, tpr, _ = roc_curve(y_test,classificacao)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yXzSUrVtrJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94d8feaf-0a53-4cb5-9ac8-31fd77f4b329"
      },
      "source": [
        "fpr"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.35616438, 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM_u7TmutvxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4486599-1447-4e03-e178-40b1a246387e"
      },
      "source": [
        "tpr"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.62962963, 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht4q9vh7t4An",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "49dec551-98b2-4d41-8d63-f13e47a05d91"
      },
      "source": [
        "plt.plot(fpr,tpr,marker='.')\n",
        "plt.title('Curva ROC')\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.ylabel('Taxa de Verdadeiro Positivos')\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qotpnI9wuv9j",
        "colab_type": "text"
      },
      "source": [
        "## Área sob a curva (*Area under the curve - AUC)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J2hBnrMuMxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando area sob a curva ROC\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2NCVSzXuOSZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9aa0068-5dc7-4765-cb0b-0ca5304f271f"
      },
      "source": [
        "auc = roc_auc_score(y_test,classificacao)\n",
        "round(auc,3)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuH3vBobSAFQ",
        "colab_type": "text"
      },
      "source": [
        "## **Comentários**: \n",
        "## **Comentários:**\n",
        "Os resutados das méticas acurácia, precvisão, recall, f1 foram, respectivamente, 63.8%, 56.7%, 63%, 59.65%. Esses resultados foram ligeiramente superiores aos métodos anteriores (Arvore de desição e Floresta aleatoria) 61.4%, 54.4%, 57.4%, 63.7%. O mesmo acontece como AUC (RNA = 63.7% ; RF = 60.9%)\n",
        "Embora os scores obtidos pela RNA tenha sido superiores, nesse caso, à RF, os atributos parecem ser pouco significativos na caracterização do ambiente favorável à incidência de arvores emergentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhHUZ6l7u5vA",
        "colab_type": "text"
      },
      "source": [
        "## Validação Cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aalitWi-u-5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# avaliando modelo com cross validation\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itX5eFewvNZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghEEB4bLvP_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b3ff33a7-690e-4f77-98c0-f64e87d65a45"
      },
      "source": [
        "#calculando os scores\n",
        "scores = cross_val_score(classificador,X,y,cv=10)\n",
        "scores"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.515625  , 0.5       , 0.71428571, 0.66666667, 0.73015873,\n",
              "       0.49206349, 0.58730159, 0.65079365, 0.71428571, 0.55555556])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhY1xts0vrCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5952f163-0ad8-4462-9eb1-91a7162b666f"
      },
      "source": [
        "round(scores.mean(),3),round(scores.std(),3)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.613, 0.089)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ps2GaIQULEY",
        "colab_type": "text"
      },
      "source": [
        "## **Comentários**:\n",
        "Validação cruzada aprtestnopu um valor de lor de 61.3% como média da avaliação do classificador (com máximo de 71,43% e mínimo de 49,2%)\n",
        "Portanto a validação cruzada forneceu um valor da avaliação do modelo da magnitude das métricas anteriormente verificadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvirWdPrwacy",
        "colab_type": "text"
      },
      "source": [
        "## 7. Comparando MLP com Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pl24nuawjn_",
        "colab_type": "text"
      },
      "source": [
        "## Validação Cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7TQCznOwmh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzvJVds3wpjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criando árvore\n",
        "arvore = DecisionTreeClassifier()\n",
        "\n",
        "#calculando os scores\n",
        "scores_arvore = cross_val_score(arvore,X,y,cv=10)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j585wdvFwsc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criando random forest\n",
        "floresta = RandomForestClassifier()\n",
        "\n",
        "#calculando os scores\n",
        "scores_floresta = cross_val_score(floresta,X,y,cv=10)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-At4KoQw0V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criando rede neural\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)\n",
        "\n",
        "#calculando os scores\n",
        "scores_mlp = cross_val_score(mlp,X,y,cv=10)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqWKBRXyw4FA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1a6653f8-04ad-4812-dec1-36db4b28c337"
      },
      "source": [
        "print('Árvore de Decisão: ', round(scores_arvore.mean(),3),round(scores_arvore.std(),3))\n",
        "print('Random Forest: ', round(scores.mean(),3),round(scores.std(),3))\n",
        "print('MLP:', round(scores_mlp.mean(),3),round(scores_mlp.std(),3))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão:  0.571 0.067\n",
            "Random Forest:  0.613 0.089\n",
            "MLP: 0.617 0.091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoCjsyiKXe3o",
        "colab_type": "text"
      },
      "source": [
        "## **Comentários:**\n",
        "A partir da validação cruzada, percebe-se melhor desempenho da MLP sobre a RF e Arvores de decisão. Contudo, todos os resultados apresentados são baixos, o que possivelmente se deve à natureza dos atributos utilizados, bem como a dos valores de \"pseudo-ausência\" ou arvores não emergentes (ANEs), uma vez que estas foram escolhidas aleatoriamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxo45Hewxp9F",
        "colab_type": "text"
      },
      "source": [
        "## 8. Otimização de Parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD_ti--sXSOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsHwEzCWYyX9",
        "colab_type": "text"
      },
      "source": [
        "## **Comentários:**\n",
        "O resultado obtidos através da validação cruzada fornece o valor de 57,6%.\n",
        "Logo, pelos resultados das avaliação dos classificadores (próximos ao 50% - aleatoriedade) os atributos topográficos utilizados são pouco representativos na modelagem da incidência de AEs na Amazônia Brasileira. Sugere-se, portanto, o uso adicional de variáveis ambientais oriunda outras fontes tais como clima, pedologia, dentre outras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK2wRlmbbHGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBf3-_24bKmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = [\n",
        "              {\n",
        "                  'hidden_layer_sizes': [(10),(50),(100),(50,10),(100,50)],\n",
        "                  'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "                  'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "                  'max_iter': [500,1000,2000]\n",
        "              }\n",
        "              \n",
        "]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ARb-nE-bVvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = RandomizedSearchCV(MLPClassifier(),param_grid,cv=5,scoring='accuracy')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lkv10uobaoS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8676971f-c8a4-4c59-d88e-713b30e31f54"
      },
      "source": [
        "mlp.fit(X,y)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                           batch_size='auto', beta_1=0.9,\n",
              "                                           beta_2=0.999, early_stopping=False,\n",
              "                                           epsilon=1e-08,\n",
              "                                           hidden_layer_sizes=(100,),\n",
              "                                           learning_rate='constant',\n",
              "                                           learning_rate_init=0.001,\n",
              "                                           max_fun=15000, max_iter=200,\n",
              "                                           momentum=0.9, n_iter_no_change=10,\n",
              "                                           nesterovs_momentum=True, power_t=0.5,\n",
              "                                           random...\n",
              "                                           verbose=False, warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions=[{'activation': ['identity', 'logistic',\n",
              "                                                        'tanh', 'relu'],\n",
              "                                         'hidden_layer_sizes': [10, 50, 100,\n",
              "                                                                (50, 10),\n",
              "                                                                (100, 50)],\n",
              "                                         'max_iter': [500, 1000, 2000],\n",
              "                                         'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo1lH2V3fEdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f12ba29-c05e-442c-eff1-e5dd38890f25"
      },
      "source": [
        "print(mlp.best_params_)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'solver': 'lbfgs', 'max_iter': 500, 'hidden_layer_sizes': 50, 'activation': 'identity'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0BkEzZ9fazL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb10d405-3ea5-4294-91b1-764270c63f86"
      },
      "source": [
        "print(round(mlp.best_score_,3))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3AKNsY6gDaM",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG2_qCTQfEcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XrM92f_gK_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = GridSearchCV(MLPClassifier(),param_grid,cv=5,scoring='accuracy')"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYEiQBRZgM7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a223295a-4efc-4e3f-f394-f621ca7a5ef8"
      },
      "source": [
        "mlp.fit(X,y)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state...\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'activation': ['identity', 'logistic', 'tanh',\n",
              "                                         'relu'],\n",
              "                          'hidden_layer_sizes': [10, 50, 100, (50, 10),\n",
              "                                                 (100, 50)],\n",
              "                          'max_iter': [500, 1000, 2000],\n",
              "                          'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnbKi1bXkeTW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00f4dd55-0c24-4247-9adc-9a02e92ca765"
      },
      "source": [
        "print(mlp.best_params_)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'activation': 'relu', 'hidden_layer_sizes': 10, 'max_iter': 1000, 'solver': 'lbfgs'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-TAeqg0kf3s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "592ebe0f-cde8-4dfb-ab90-6db45a0c872c"
      },
      "source": [
        "print(mlp.best_score_)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6534683164604423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1RUTK0DkgDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90d29b36-919a-4ce6-bbbb-cd10ba34625a"
      },
      "source": [
        "mlp.cv_results_"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.01797056, 0.10787134, 0.36640778, 0.01772976, 0.09698615,\n",
              "        0.31710534, 0.01397443, 0.03757777, 0.31248693, 0.02926931,\n",
              "        0.14650574, 0.33818974, 0.03307033, 0.14202199, 0.33350868,\n",
              "        0.03210969, 0.10548344, 0.33091321, 0.0499413 , 0.22194777,\n",
              "        0.30660524, 0.05303845, 0.12288275, 0.30731072, 0.04535112,\n",
              "        0.07786503, 0.33175397, 0.03440895, 0.43982944, 0.18551168,\n",
              "        0.03194771, 0.34713349, 0.18633389, 0.02702279, 0.59878216,\n",
              "        0.19083848, 0.08907008, 1.37495179, 0.22517271, 0.1012104 ,\n",
              "        1.54569001, 0.22779002, 0.1003809 , 1.35134435, 0.23978171,\n",
              "        0.28380437, 0.05125928, 0.03985758, 0.47055998, 0.04889393,\n",
              "        0.03556228, 0.66660852, 0.06750751, 0.04710922, 1.0173543 ,\n",
              "        0.08014202, 1.35607791, 1.94537301, 0.08044147, 1.41579585,\n",
              "        3.31539488, 0.06099997, 1.26518741, 1.8692132 , 0.08048058,\n",
              "        1.74972463, 3.06475844, 0.08666801, 1.79518023, 3.6092587 ,\n",
              "        0.07716374, 1.68447251, 0.82344031, 0.07259583, 0.06454492,\n",
              "        1.5679038 , 0.09001679, 0.0382678 , 2.5885766 , 0.11992817,\n",
              "        0.05493851, 2.66740336, 0.16133795, 0.50651388, 6.3025744 ,\n",
              "        0.13698606, 1.19475293, 8.63936205, 0.17232509, 0.87605901,\n",
              "        0.29715562, 0.05647144, 0.42158709, 0.53512564, 0.07474861,\n",
              "        0.39814982, 0.91176004, 0.07511449, 0.41300325, 1.1915391 ,\n",
              "        0.16222229, 0.63817625, 2.17692075, 0.18878641, 0.58737941,\n",
              "        3.09613957, 0.13305335, 0.57808952, 2.3826705 , 0.1850409 ,\n",
              "        0.67636652, 3.40551729, 0.19067488, 0.72400641, 3.14352913,\n",
              "        0.19546504, 0.66925235, 1.02982831, 0.5591692 , 0.34078283,\n",
              "        1.20352244, 0.75514073, 0.31792102, 1.66600456, 0.39312558,\n",
              "        0.31878972, 3.57368531, 2.91046672, 0.49922261, 4.31171794,\n",
              "        2.53692179, 0.46553183, 4.35943751, 2.39925475, 0.56358409,\n",
              "        0.24968672, 0.06468019, 0.44479346, 0.30566511, 0.10686102,\n",
              "        0.52914791, 0.32322016, 0.08475399, 0.51999311, 0.6822648 ,\n",
              "        0.08310266, 1.18180795, 1.3351018 , 0.05780544, 1.93903627,\n",
              "        2.51335936, 0.1167439 , 2.16784163, 1.12882004, 0.11448808,\n",
              "        1.5516335 , 2.21488805, 0.1120213 , 2.84802108, 4.62315078,\n",
              "        0.09284568, 3.32685981, 0.60624723, 0.13732228, 1.03564234,\n",
              "        1.20073314, 0.16160274, 1.89425778, 2.42178898, 0.1271884 ,\n",
              "        1.51396942, 2.22079067, 0.35999103, 2.64316955, 3.49868731,\n",
              "        0.31548276, 3.81016865, 8.70407386, 0.18039451, 2.88672552]),\n",
              " 'mean_score_time': array([0.00146794, 0.00130429, 0.00149331, 0.00142813, 0.00131006,\n",
              "        0.00137596, 0.00127325, 0.00129304, 0.00131478, 0.00172081,\n",
              "        0.00179515, 0.00184412, 0.00181398, 0.00175886, 0.00175381,\n",
              "        0.00175934, 0.00177479, 0.00176644, 0.00293379, 0.00184259,\n",
              "        0.00179796, 0.00183868, 0.00177326, 0.00180736, 0.0017848 ,\n",
              "        0.0017652 , 0.0018415 , 0.00156622, 0.00176368, 0.00135946,\n",
              "        0.00134954, 0.00134068, 0.00136123, 0.00137596, 0.00137959,\n",
              "        0.00133715, 0.0019453 , 0.0018929 , 0.00194926, 0.00189919,\n",
              "        0.00189643, 0.00191011, 0.00189304, 0.00193095, 0.00199647,\n",
              "        0.00213461, 0.00135384, 0.00142002, 0.00201459, 0.00152092,\n",
              "        0.00135612, 0.00163388, 0.00133162, 0.00133085, 0.00223975,\n",
              "        0.00207939, 0.00210228, 0.00233335, 0.00309567, 0.0020503 ,\n",
              "        0.00205913, 0.00200005, 0.0019959 , 0.00221415, 0.00227928,\n",
              "        0.0022891 , 0.00227509, 0.00226073, 0.00232611, 0.00222883,\n",
              "        0.00226841, 0.00227513, 0.00184498, 0.0015234 , 0.00155764,\n",
              "        0.00209475, 0.00153055, 0.00156813, 0.00181441, 0.00155587,\n",
              "        0.00155783, 0.00274272, 0.00268703, 0.00260534, 0.00279784,\n",
              "        0.00264149, 0.00266733, 0.0026083 , 0.00259199, 0.00261497,\n",
              "        0.00194101, 0.00134153, 0.0014595 , 0.00178599, 0.00138245,\n",
              "        0.00144839, 0.00155954, 0.0013207 , 0.00134854, 0.00214958,\n",
              "        0.00207853, 0.00208035, 0.00210762, 0.0021955 , 0.002039  ,\n",
              "        0.00215192, 0.0020833 , 0.00211248, 0.0024436 , 0.002316  ,\n",
              "        0.00236826, 0.00255828, 0.00234561, 0.00267863, 0.00256538,\n",
              "        0.00236273, 0.00237904, 0.00201602, 0.00165987, 0.00156951,\n",
              "        0.00161991, 0.00157189, 0.00156083, 0.00165925, 0.00180607,\n",
              "        0.00157223, 0.00374365, 0.00270991, 0.00271344, 0.00283213,\n",
              "        0.00270715, 0.00266023, 0.00288038, 0.00284824, 0.00267434,\n",
              "        0.00193191, 0.00135427, 0.00133533, 0.00169582, 0.0014606 ,\n",
              "        0.00142117, 0.00134835, 0.00134249, 0.00145988, 0.00202012,\n",
              "        0.00191007, 0.00193772, 0.00188928, 0.00188904, 0.00186467,\n",
              "        0.00183458, 0.00195136, 0.00204034, 0.00195212, 0.00195184,\n",
              "        0.00220623, 0.00189228, 0.00191894, 0.00193434, 0.00280843,\n",
              "        0.00195084, 0.00232296, 0.00198045, 0.00145512, 0.00203037,\n",
              "        0.00203757, 0.00148125, 0.00166211, 0.00201349, 0.00145712,\n",
              "        0.00144854, 0.00239787, 0.00260777, 0.00230422, 0.00222445,\n",
              "        0.00220599, 0.00216217, 0.00213361, 0.00215163, 0.00223207]),\n",
              " 'mean_test_score': array([0.62023497, 0.52387202, 0.59661292, 0.62023497, 0.56165479,\n",
              "        0.60292463, 0.62023497, 0.52535933, 0.60134983, 0.62023497,\n",
              "        0.52694663, 0.61402325, 0.62023497, 0.51412323, 0.61083615,\n",
              "        0.62023497, 0.52367204, 0.61243595, 0.62023497, 0.54283215,\n",
              "        0.61871016, 0.62023497, 0.55065617, 0.62503437, 0.62023497,\n",
              "        0.55063117, 0.61876015, 0.62023497, 0.59500062, 0.62978378,\n",
              "        0.62023497, 0.58852643, 0.62190976, 0.62023497, 0.62654668,\n",
              "        0.62345957, 0.62180977, 0.59182602, 0.61558555, 0.62023497,\n",
              "        0.59980002, 0.62348456, 0.62023497, 0.58565179, 0.62348456,\n",
              "        0.57905262, 0.5031746 , 0.55219348, 0.59652543, 0.5       ,\n",
              "        0.51892263, 0.59176353, 0.5       , 0.49538808, 0.56809149,\n",
              "        0.5615798 , 0.60449944, 0.57765279, 0.49993751, 0.60448694,\n",
              "        0.59013873, 0.51417323, 0.60133733, 0.57911511, 0.50943632,\n",
              "        0.60766154, 0.56170479, 0.52859643, 0.60609924, 0.58075241,\n",
              "        0.54589426, 0.60609924, 0.57909011, 0.5       , 0.50629921,\n",
              "        0.54271966, 0.5015748 , 0.52063492, 0.54429446, 0.4984252 ,\n",
              "        0.5535933 , 0.55541807, 0.48413948, 0.51574803, 0.55685539,\n",
              "        0.4968379 , 0.54735658, 0.53792026, 0.50634921, 0.55239345,\n",
              "        0.61551056, 0.48896388, 0.60762405, 0.53492063, 0.5096363 ,\n",
              "        0.60131234, 0.58847644, 0.45419323, 0.59981252, 0.56024247,\n",
              "        0.53314586, 0.60926134, 0.52528434, 0.51239845, 0.61713536,\n",
              "        0.51734783, 0.52839645, 0.60924884, 0.56655418, 0.53953256,\n",
              "        0.62033496, 0.54749406, 0.51589801, 0.62505937, 0.53647044,\n",
              "        0.54269466, 0.61399825, 0.54910636, 0.56200475, 0.60922385,\n",
              "        0.56795401, 0.55858018, 0.61873516, 0.53794526, 0.49372578,\n",
              "        0.61398575, 0.55376828, 0.59018873, 0.61873516, 0.54416948,\n",
              "        0.5855893 , 0.62499688, 0.59485064, 0.57450319, 0.62032246,\n",
              "        0.57112861, 0.48873891, 0.59976253, 0.65346832, 0.46361705,\n",
              "        0.60452443, 0.59016373, 0.52217223, 0.60287464, 0.59008874,\n",
              "        0.53634546, 0.61709786, 0.56341707, 0.4920385 , 0.61238595,\n",
              "        0.5744282 , 0.52995876, 0.60439945, 0.60127484, 0.48272716,\n",
              "        0.61872266, 0.60743657, 0.52224722, 0.58547682, 0.56644169,\n",
              "        0.50307462, 0.60761155, 0.55084364, 0.50786152, 0.59663792,\n",
              "        0.55213098, 0.5047744 , 0.61228596, 0.60439945, 0.47145357,\n",
              "        0.60917385, 0.5632046 , 0.53294588, 0.61867267, 0.58858893,\n",
              "        0.5047619 , 0.61863517, 0.55540557, 0.5079615 , 0.58702662]),\n",
              " 'param_activation': masked_array(data=['identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_hidden_layer_sizes': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), 10, 10, 10, 10, 10, 10, 10, 10, 10, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_iter': masked_array(data=[500, 500, 500, 1000, 1000, 1000, 2000, 2000, 2000, 500,\n",
              "                    500, 500, 1000, 1000, 1000, 2000, 2000, 2000, 500, 500,\n",
              "                    500, 1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'}],\n",
              " 'rank_test_score': array([ 14, 142,  71,  14, 104,  61,  14, 140,  63,  14, 139,  39,  14,\n",
              "        152,  45,  14, 143,  42,  14, 125,  32,  14, 117,   5,  14, 118,\n",
              "         28,  14,  73,   2,  14,  82,  10,  14,   3,   9,  11,  75,  37,\n",
              "         14,  68,   7,  14,  85,   7,  91, 162, 114,  72, 165, 147,  76,\n",
              "        165, 171,  96, 105,  57,  92, 168,  58,  79, 151,  64,  89, 155,\n",
              "         50, 103, 137,  54,  88, 122,  54,  90, 165, 159, 126, 164, 146,\n",
              "        123, 169, 112, 109, 176, 150, 108, 170, 121, 130, 158, 113,  38,\n",
              "        174,  51, 133, 154,  65,  83, 180,  67, 106, 134,  46, 141, 153,\n",
              "         35, 148, 138,  47,  98, 128,  12, 120, 149,   4, 131, 127,  40,\n",
              "        119, 102,  48,  97, 107,  29, 129, 172,  41, 111,  77,  29, 124,\n",
              "         86,   6,  74,  93,  13,  95, 175,  69,   1, 179,  56,  78, 145,\n",
              "         62,  80, 132,  36, 100, 173,  43,  94, 136,  59,  66, 177,  31,\n",
              "         53, 144,  87,  99, 163,  52, 116, 157,  70, 115, 160,  44,  60,\n",
              "        178,  49, 101, 135,  33,  81, 161,  34, 110, 156,  84], dtype=int32),\n",
              " 'split0_test_score': array([0.51181102, 0.52755906, 0.50393701, 0.51181102, 0.57480315,\n",
              "        0.49606299, 0.51181102, 0.51181102, 0.48818898, 0.51181102,\n",
              "        0.56692913, 0.48031496, 0.51181102, 0.48031496, 0.48031496,\n",
              "        0.51181102, 0.46456693, 0.48031496, 0.51181102, 0.57480315,\n",
              "        0.49606299, 0.51181102, 0.48031496, 0.51968504, 0.51181102,\n",
              "        0.52755906, 0.48031496, 0.51181102, 0.56692913, 0.51968504,\n",
              "        0.51181102, 0.51968504, 0.50393701, 0.51181102, 0.54330709,\n",
              "        0.51181102, 0.51968504, 0.50393701, 0.47244094, 0.51181102,\n",
              "        0.52755906, 0.49606299, 0.51181102, 0.52755906, 0.48818898,\n",
              "        0.57480315, 0.50393701, 0.54330709, 0.54330709, 0.50393701,\n",
              "        0.59055118, 0.60629921, 0.50393701, 0.45669291, 0.55905512,\n",
              "        0.53543307, 0.51181102, 0.48818898, 0.52755906, 0.51181102,\n",
              "        0.59055118, 0.51968504, 0.51181102, 0.52755906, 0.51181102,\n",
              "        0.51181102, 0.52755906, 0.45669291, 0.49606299, 0.58267717,\n",
              "        0.54330709, 0.48818898, 0.50393701, 0.50393701, 0.51968504,\n",
              "        0.48818898, 0.50393701, 0.50393701, 0.51181102, 0.49606299,\n",
              "        0.58267717, 0.51968504, 0.49606299, 0.50393701, 0.49606299,\n",
              "        0.49606299, 0.48031496, 0.48818898, 0.49606299, 0.49606299,\n",
              "        0.56692913, 0.49606299, 0.49606299, 0.43307087, 0.49606299,\n",
              "        0.49606299, 0.63779528, 0.40944882, 0.46456693, 0.48818898,\n",
              "        0.5511811 , 0.46456693, 0.51181102, 0.49606299, 0.50393701,\n",
              "        0.49606299, 0.64566929, 0.48818898, 0.50393701, 0.48818898,\n",
              "        0.49606299, 0.46456693, 0.52755906, 0.50393701, 0.40944882,\n",
              "        0.60629921, 0.47244094, 0.46456693, 0.48818898, 0.49606299,\n",
              "        0.53543307, 0.5511811 , 0.49606299, 0.48031496, 0.37795276,\n",
              "        0.48818898, 0.54330709, 0.53543307, 0.50393701, 0.52755906,\n",
              "        0.51968504, 0.52755906, 0.5984252 , 0.53543307, 0.48031496,\n",
              "        0.52755906, 0.50393701, 0.50393701, 0.63779528, 0.50393701,\n",
              "        0.49606299, 0.53543307, 0.45669291, 0.51181102, 0.62204724,\n",
              "        0.50393701, 0.53543307, 0.51181102, 0.57480315, 0.51181102,\n",
              "        0.54330709, 0.51181102, 0.56692913, 0.57480315, 0.41732283,\n",
              "        0.51181102, 0.60629921, 0.43307087, 0.51181102, 0.53543307,\n",
              "        0.54330709, 0.55905512, 0.40944882, 0.51968504, 0.49606299,\n",
              "        0.51968504, 0.48818898, 0.60629921, 0.58267717, 0.48031496,\n",
              "        0.59055118, 0.5511811 , 0.67716535, 0.60629921, 0.56692913,\n",
              "        0.55905512, 0.63779528, 0.54330709, 0.42519685, 0.52755906]),\n",
              " 'split1_test_score': array([0.74015748, 0.43307087, 0.62992126, 0.74015748, 0.58267717,\n",
              "        0.66141732, 0.74015748, 0.51181102, 0.66141732, 0.74015748,\n",
              "        0.45669291, 0.68503937, 0.74015748, 0.62204724, 0.69291339,\n",
              "        0.74015748, 0.62204724, 0.68503937, 0.74015748, 0.44094488,\n",
              "        0.71653543, 0.74015748, 0.60629921, 0.70866142, 0.74015748,\n",
              "        0.57480315, 0.7007874 , 0.74015748, 0.58267717, 0.71653543,\n",
              "        0.74015748, 0.70866142, 0.69291339, 0.74015748, 0.73228346,\n",
              "        0.70866142, 0.74015748, 0.64566929, 0.70866142, 0.74015748,\n",
              "        0.5984252 , 0.70866142, 0.74015748, 0.51181102, 0.71653543,\n",
              "        0.62204724, 0.49606299, 0.57480315, 0.64566929, 0.49606299,\n",
              "        0.48818898, 0.58267717, 0.49606299, 0.4488189 , 0.54330709,\n",
              "        0.66929134, 0.65354331, 0.59055118, 0.51181102, 0.66141732,\n",
              "        0.62204724, 0.5511811 , 0.64566929, 0.62992126, 0.54330709,\n",
              "        0.66141732, 0.5984252 , 0.52755906, 0.66141732, 0.54330709,\n",
              "        0.54330709, 0.66929134, 0.66929134, 0.49606299, 0.51181102,\n",
              "        0.5984252 , 0.50393701, 0.49606299, 0.58267717, 0.49606299,\n",
              "        0.65354331, 0.56692913, 0.49606299, 0.57480315, 0.68503937,\n",
              "        0.49606299, 0.68503937, 0.62204724, 0.50393701, 0.49606299,\n",
              "        0.66141732, 0.45669291, 0.7007874 , 0.56692913, 0.43307087,\n",
              "        0.67716535, 0.62204724, 0.4488189 , 0.65354331, 0.55905512,\n",
              "        0.56692913, 0.7007874 , 0.55905512, 0.69291339, 0.7007874 ,\n",
              "        0.57480315, 0.46456693, 0.68503937, 0.56692913, 0.60629921,\n",
              "        0.69291339, 0.61417323, 0.45669291, 0.70866142, 0.61417323,\n",
              "        0.49606299, 0.70866142, 0.5984252 , 0.4488189 , 0.69291339,\n",
              "        0.65354331, 0.54330709, 0.7007874 , 0.61417323, 0.57480315,\n",
              "        0.7007874 , 0.58267717, 0.64566929, 0.69291339, 0.64566929,\n",
              "        0.55905512, 0.72440945, 0.64566929, 0.52755906, 0.71653543,\n",
              "        0.66141732, 0.59055118, 0.64566929, 0.67716535, 0.41732283,\n",
              "        0.65354331, 0.66141732, 0.57480315, 0.67716535, 0.62204724,\n",
              "        0.5984252 , 0.69291339, 0.53543307, 0.44094488, 0.68503937,\n",
              "        0.56692913, 0.61417323, 0.66141732, 0.62204724, 0.46456693,\n",
              "        0.69291339, 0.70866142, 0.5511811 , 0.63779528, 0.60629921,\n",
              "        0.51968504, 0.64566929, 0.55905512, 0.52755906, 0.62204724,\n",
              "        0.63779528, 0.50393701, 0.65354331, 0.64566929, 0.50393701,\n",
              "        0.62992126, 0.62992126, 0.56692913, 0.62992126, 0.62204724,\n",
              "        0.44094488, 0.62204724, 0.5511811 , 0.55905512, 0.64566929]),\n",
              " 'split2_test_score': array([0.61904762, 0.52380952, 0.62698413, 0.61904762, 0.50793651,\n",
              "        0.63492063, 0.61904762, 0.55555556, 0.64285714, 0.61904762,\n",
              "        0.57936508, 0.63492063, 0.61904762, 0.53174603, 0.63492063,\n",
              "        0.61904762, 0.57936508, 0.63492063, 0.61904762, 0.6031746 ,\n",
              "        0.61904762, 0.61904762, 0.50793651, 0.63492063, 0.61904762,\n",
              "        0.55555556, 0.64285714, 0.61904762, 0.61904762, 0.64285714,\n",
              "        0.61904762, 0.54761905, 0.62698413, 0.61904762, 0.65873016,\n",
              "        0.64285714, 0.61904762, 0.64285714, 0.63492063, 0.61904762,\n",
              "        0.64285714, 0.63492063, 0.61904762, 0.64285714, 0.62698413,\n",
              "        0.55555556, 0.5       , 0.51587302, 0.62698413, 0.5       ,\n",
              "        0.5       , 0.6031746 , 0.5       , 0.54761905, 0.5952381 ,\n",
              "        0.57936508, 0.65079365, 0.62698413, 0.52380952, 0.63492063,\n",
              "        0.52380952, 0.47619048, 0.64285714, 0.57936508, 0.48412698,\n",
              "        0.62698413, 0.56349206, 0.47619048, 0.62698413, 0.61111111,\n",
              "        0.53968254, 0.62698413, 0.56349206, 0.5       , 0.5       ,\n",
              "        0.52380952, 0.5       , 0.53968254, 0.55555556, 0.5       ,\n",
              "        0.5952381 , 0.57936508, 0.5       , 0.5       , 0.50793651,\n",
              "        0.49206349, 0.5       , 0.51587302, 0.53174603, 0.62698413,\n",
              "        0.6031746 , 0.50793651, 0.62698413, 0.57142857, 0.53968254,\n",
              "        0.62698413, 0.57142857, 0.5       , 0.64285714, 0.65079365,\n",
              "        0.5952381 , 0.63492063, 0.48412698, 0.50793651, 0.62698413,\n",
              "        0.46825397, 0.57142857, 0.63492063, 0.61904762, 0.47619048,\n",
              "        0.64285714, 0.62698413, 0.56349206, 0.63492063, 0.6031746 ,\n",
              "        0.5       , 0.63492063, 0.54761905, 0.65079365, 0.62698413,\n",
              "        0.61904762, 0.64285714, 0.63492063, 0.55555556, 0.43650794,\n",
              "        0.62698413, 0.5952381 , 0.65079365, 0.63492063, 0.53968254,\n",
              "        0.61904762, 0.63492063, 0.58730159, 0.57142857, 0.63492063,\n",
              "        0.57936508, 0.50793651, 0.61111111, 0.65873016, 0.48412698,\n",
              "        0.65873016, 0.58730159, 0.56349206, 0.6031746 , 0.57936508,\n",
              "        0.49206349, 0.64285714, 0.6031746 , 0.5       , 0.61904762,\n",
              "        0.61111111, 0.58730159, 0.58730159, 0.62698413, 0.52380952,\n",
              "        0.64285714, 0.6031746 , 0.48412698, 0.6031746 , 0.55555556,\n",
              "        0.52380952, 0.63492063, 0.66666667, 0.44444444, 0.64285714,\n",
              "        0.54761905, 0.5       , 0.61904762, 0.55555556, 0.5       ,\n",
              "        0.61111111, 0.56349206, 0.46825397, 0.64285714, 0.57936508,\n",
              "        0.48412698, 0.63492063, 0.61904762, 0.45238095, 0.56349206]),\n",
              " 'split3_test_score': array([0.5952381 , 0.47619048, 0.57936508, 0.5952381 , 0.48412698,\n",
              "        0.6031746 , 0.5952381 , 0.5       , 0.58730159, 0.5952381 ,\n",
              "        0.43650794, 0.61111111, 0.5952381 , 0.46031746, 0.6031746 ,\n",
              "        0.5952381 , 0.56349206, 0.62698413, 0.5952381 , 0.49206349,\n",
              "        0.61111111, 0.5952381 , 0.58730159, 0.61904762, 0.5952381 ,\n",
              "        0.53174603, 0.61904762, 0.5952381 , 0.58730159, 0.61904762,\n",
              "        0.5952381 , 0.56349206, 0.61904762, 0.5952381 , 0.58730159,\n",
              "        0.61904762, 0.5952381 , 0.55555556, 0.61111111, 0.5952381 ,\n",
              "        0.6031746 , 0.61904762, 0.5952381 , 0.6031746 , 0.63492063,\n",
              "        0.55555556, 0.51587302, 0.56349206, 0.53174603, 0.5       ,\n",
              "        0.46825397, 0.55555556, 0.5       , 0.38888889, 0.6031746 ,\n",
              "        0.5       , 0.58730159, 0.53174603, 0.54761905, 0.57936508,\n",
              "        0.57936508, 0.55555556, 0.57142857, 0.6031746 , 0.5       ,\n",
              "        0.58730159, 0.54761905, 0.57142857, 0.58730159, 0.58730159,\n",
              "        0.47619048, 0.5952381 , 0.57142857, 0.5       , 0.5       ,\n",
              "        0.52380952, 0.5       , 0.45238095, 0.54761905, 0.5       ,\n",
              "        0.51587302, 0.55555556, 0.5       , 0.5       , 0.54761905,\n",
              "        0.5       , 0.57142857, 0.51587302, 0.5       , 0.5       ,\n",
              "        0.55555556, 0.38095238, 0.6031746 , 0.54761905, 0.55555556,\n",
              "        0.58730159, 0.54761905, 0.42857143, 0.5952381 , 0.52380952,\n",
              "        0.55555556, 0.61111111, 0.53968254, 0.4047619 , 0.61111111,\n",
              "        0.53968254, 0.45238095, 0.6031746 , 0.53174603, 0.56349206,\n",
              "        0.61904762, 0.53174603, 0.6031746 , 0.61904762, 0.56349206,\n",
              "        0.53174603, 0.61904762, 0.58730159, 0.61904762, 0.58730159,\n",
              "        0.46031746, 0.44444444, 0.61904762, 0.51587302, 0.46031746,\n",
              "        0.61904762, 0.45238095, 0.52380952, 0.61904762, 0.5       ,\n",
              "        0.58730159, 0.5952381 , 0.56349206, 0.6031746 , 0.5952381 ,\n",
              "        0.5       , 0.37301587, 0.61904762, 0.62698413, 0.44444444,\n",
              "        0.5952381 , 0.57936508, 0.45238095, 0.57142857, 0.55555556,\n",
              "        0.48412698, 0.57936508, 0.57936508, 0.53174603, 0.5952381 ,\n",
              "        0.53968254, 0.52380952, 0.6031746 , 0.55555556, 0.52380952,\n",
              "        0.61111111, 0.52380952, 0.53968254, 0.58730159, 0.54761905,\n",
              "        0.48412698, 0.5952381 , 0.50793651, 0.58730159, 0.58730159,\n",
              "        0.5       , 0.5       , 0.61111111, 0.58730159, 0.48412698,\n",
              "        0.56349206, 0.55555556, 0.48412698, 0.61904762, 0.56349206,\n",
              "        0.5       , 0.57142857, 0.52380952, 0.53174603, 0.61111111]),\n",
              " 'split4_test_score': array([0.63492063, 0.65873016, 0.64285714, 0.63492063, 0.65873016,\n",
              "        0.61904762, 0.63492063, 0.54761905, 0.62698413, 0.63492063,\n",
              "        0.5952381 , 0.65873016, 0.63492063, 0.47619048, 0.64285714,\n",
              "        0.63492063, 0.38888889, 0.63492063, 0.63492063, 0.6031746 ,\n",
              "        0.65079365, 0.63492063, 0.57142857, 0.64285714, 0.63492063,\n",
              "        0.56349206, 0.65079365, 0.63492063, 0.61904762, 0.65079365,\n",
              "        0.63492063, 0.6031746 , 0.66666667, 0.63492063, 0.61111111,\n",
              "        0.63492063, 0.63492063, 0.61111111, 0.65079365, 0.63492063,\n",
              "        0.62698413, 0.65873016, 0.63492063, 0.64285714, 0.65079365,\n",
              "        0.58730159, 0.5       , 0.56349206, 0.63492063, 0.5       ,\n",
              "        0.54761905, 0.61111111, 0.5       , 0.63492063, 0.53968254,\n",
              "        0.52380952, 0.61904762, 0.65079365, 0.38888889, 0.63492063,\n",
              "        0.63492063, 0.46825397, 0.63492063, 0.55555556, 0.50793651,\n",
              "        0.65079365, 0.57142857, 0.61111111, 0.65873016, 0.57936508,\n",
              "        0.62698413, 0.65079365, 0.58730159, 0.5       , 0.5       ,\n",
              "        0.57936508, 0.5       , 0.61111111, 0.52380952, 0.5       ,\n",
              "        0.42063492, 0.55555556, 0.42857143, 0.5       , 0.54761905,\n",
              "        0.5       , 0.5       , 0.54761905, 0.5       , 0.64285714,\n",
              "        0.69047619, 0.6031746 , 0.61111111, 0.55555556, 0.52380952,\n",
              "        0.61904762, 0.56349206, 0.48412698, 0.64285714, 0.57936508,\n",
              "        0.3968254 , 0.63492063, 0.53174603, 0.46031746, 0.64285714,\n",
              "        0.50793651, 0.50793651, 0.63492063, 0.61111111, 0.56349206,\n",
              "        0.65079365, 0.5       , 0.42857143, 0.65873016, 0.49206349,\n",
              "        0.57936508, 0.63492063, 0.54761905, 0.6031746 , 0.64285714,\n",
              "        0.57142857, 0.61111111, 0.64285714, 0.52380952, 0.61904762,\n",
              "        0.63492063, 0.5952381 , 0.5952381 , 0.64285714, 0.50793651,\n",
              "        0.64285714, 0.64285714, 0.57936508, 0.63492063, 0.67460317,\n",
              "        0.58730159, 0.46825397, 0.61904762, 0.66666667, 0.46825397,\n",
              "        0.61904762, 0.58730159, 0.56349206, 0.65079365, 0.57142857,\n",
              "        0.6031746 , 0.63492063, 0.58730159, 0.41269841, 0.65079365,\n",
              "        0.61111111, 0.41269841, 0.6031746 , 0.62698413, 0.48412698,\n",
              "        0.63492063, 0.5952381 , 0.6031746 , 0.58730159, 0.58730159,\n",
              "        0.44444444, 0.6031746 , 0.61111111, 0.46031746, 0.63492063,\n",
              "        0.55555556, 0.53174603, 0.57142857, 0.65079365, 0.38888889,\n",
              "        0.65079365, 0.51587302, 0.46825397, 0.5952381 , 0.61111111,\n",
              "        0.53968254, 0.62698413, 0.53968254, 0.57142857, 0.58730159]),\n",
              " 'std_fit_time': array([2.52307553e-03, 6.46959098e-02, 6.22738116e-02, 4.79442396e-03,\n",
              "        6.18149989e-02, 2.29726003e-02, 1.12591427e-03, 8.48970271e-03,\n",
              "        3.84519118e-02, 2.34968908e-03, 6.55594906e-02, 3.04224168e-02,\n",
              "        4.69984860e-03, 9.62691042e-02, 1.15614743e-02, 3.39906437e-03,\n",
              "        7.54358282e-02, 1.40594047e-02, 9.24985210e-03, 1.01451998e-01,\n",
              "        2.81434610e-02, 8.85528212e-03, 1.18619352e-01, 2.33255658e-02,\n",
              "        4.34869939e-03, 1.07131507e-02, 2.13520037e-02, 8.26841008e-03,\n",
              "        1.89349744e-01, 1.80317684e-02, 1.80458677e-03, 2.42584187e-01,\n",
              "        4.39938741e-02, 7.90888145e-04, 1.95797342e-01, 2.09739104e-02,\n",
              "        2.16006910e-03, 2.86184947e-01, 2.93796389e-02, 1.54049075e-02,\n",
              "        4.41202339e-01, 3.46907660e-02, 1.65529186e-02, 5.95158782e-01,\n",
              "        1.77132549e-02, 1.55516623e-02, 2.26004905e-02, 1.76328609e-02,\n",
              "        9.38333585e-02, 1.42878383e-02, 7.29281070e-03, 2.20433604e-01,\n",
              "        7.66174536e-03, 1.59773954e-02, 1.42642023e-02, 1.03529709e-02,\n",
              "        5.38441943e-02, 1.94852452e-01, 4.00327604e-03, 6.39055910e-02,\n",
              "        8.75658502e-01, 1.62366292e-02, 1.09184713e-01, 4.61469848e-02,\n",
              "        7.75515149e-03, 1.11423105e-01, 1.86629680e-01, 6.44781045e-03,\n",
              "        7.48947137e-02, 6.25643027e-01, 1.52620619e-02, 1.20601459e-01,\n",
              "        5.30775329e-02, 5.74419212e-02, 1.55534998e-02, 1.59207155e-01,\n",
              "        4.92149893e-02, 5.67603647e-03, 8.16933538e-01, 5.00581937e-02,\n",
              "        1.16131150e-02, 1.26627129e+00, 4.59355131e-02, 7.11793996e-01,\n",
              "        6.73894541e-01, 3.85803192e-02, 8.74632455e-01, 3.71130036e+00,\n",
              "        4.79227559e-02, 9.37247031e-01, 1.57441794e-02, 2.10019731e-02,\n",
              "        9.66988239e-02, 7.25058935e-02, 1.29558765e-02, 1.41457995e-02,\n",
              "        2.80470067e-01, 2.09870574e-02, 4.79529715e-02, 2.97994660e-02,\n",
              "        5.65239062e-02, 1.76745727e-02, 2.02265796e-01, 5.93949578e-02,\n",
              "        5.48404994e-02, 1.09191205e+00, 1.69421683e-02, 4.92703765e-02,\n",
              "        5.83582069e-02, 4.77532200e-02, 7.63323591e-02, 6.09972655e-01,\n",
              "        6.40668594e-02, 4.96548004e-02, 4.66497358e-01, 7.97575388e-02,\n",
              "        5.60018592e-02, 1.34876600e-01, 3.76809380e-01, 4.73196596e-02,\n",
              "        2.84762109e-01, 5.70264327e-01, 6.48765987e-02, 9.32895754e-01,\n",
              "        4.13272342e-01, 8.03403733e-02, 2.35267241e-01, 6.68835143e-01,\n",
              "        1.07519219e-01, 7.76879336e-01, 1.19509875e+00, 9.51162181e-02,\n",
              "        1.30580509e+00, 1.36818633e+00, 1.16132508e-01, 2.83143844e-02,\n",
              "        2.57771832e-02, 3.12014030e-02, 1.59266954e-01, 3.46194212e-02,\n",
              "        8.33178238e-02, 1.14619141e-01, 2.40680409e-02, 4.83203560e-02,\n",
              "        2.75358231e-02, 3.59924934e-02, 1.11298951e-02, 6.39452784e-03,\n",
              "        4.64684849e-02, 6.74306927e-01, 3.53942306e-01, 3.31193655e-02,\n",
              "        4.06807044e-01, 2.76486671e-02, 5.27221980e-02, 1.01878556e-02,\n",
              "        6.71492944e-02, 6.39319407e-02, 3.52440079e-01, 6.71009399e-02,\n",
              "        4.43312118e-02, 3.97323617e-01, 1.23208341e-02, 4.54907959e-02,\n",
              "        2.61833951e-02, 2.43423746e-02, 7.59218568e-02, 2.75407520e-01,\n",
              "        4.08966617e-02, 3.21296100e-02, 5.83660715e-01, 1.41941406e-02,\n",
              "        1.24151117e-01, 3.55147318e-02, 1.72795372e+00, 1.30068553e-01,\n",
              "        7.46310351e-01, 1.12375773e-01, 7.85031639e-02, 3.58363198e-01]),\n",
              " 'std_score_time': array([1.04343585e-04, 2.13293903e-05, 2.23033290e-04, 1.50317573e-04,\n",
              "        1.72140195e-05, 3.78211531e-05, 4.55157490e-05, 1.44235161e-05,\n",
              "        1.57548325e-05, 2.76945938e-05, 9.24119270e-05, 8.76944112e-05,\n",
              "        9.25389213e-05, 1.96341138e-05, 4.18509844e-05, 3.46668813e-05,\n",
              "        1.68533437e-05, 3.78621915e-05, 2.29369015e-03, 7.98952860e-05,\n",
              "        4.87164248e-05, 8.34080744e-05, 3.13455064e-05, 1.02421247e-05,\n",
              "        6.49104817e-05, 2.27253806e-05, 4.88182986e-05, 2.26455905e-04,\n",
              "        3.45057786e-04, 2.51099025e-05, 2.05829122e-05, 1.82370110e-05,\n",
              "        2.22793711e-05, 5.13517092e-05, 1.42920753e-05, 1.66022894e-05,\n",
              "        4.45053861e-05, 6.42599950e-05, 2.93459859e-05, 2.19061917e-05,\n",
              "        2.19694150e-05, 1.24440795e-05, 1.91786964e-05, 2.80305632e-05,\n",
              "        5.31972493e-05, 3.12948572e-04, 2.45298308e-05, 3.68101609e-05,\n",
              "        3.77740194e-04, 2.39046719e-04, 2.69372903e-05, 5.13941761e-04,\n",
              "        1.49101421e-05, 1.85574828e-05, 1.74611843e-04, 1.34177401e-04,\n",
              "        1.43560821e-04, 6.13403020e-04, 2.17684646e-03, 1.04414447e-04,\n",
              "        1.60082948e-04, 9.95482510e-06, 2.15937222e-05, 1.39301755e-05,\n",
              "        3.07436112e-05, 6.67312095e-05, 5.52342527e-05, 4.35726897e-05,\n",
              "        1.15297963e-04, 2.80608033e-05, 4.81916082e-05, 2.92793547e-05,\n",
              "        2.91831844e-04, 4.20681729e-05, 6.77433406e-05, 2.75739225e-04,\n",
              "        2.35504461e-05, 1.06899340e-04, 2.13273456e-04, 2.66617219e-05,\n",
              "        5.91299226e-05, 2.71182427e-04, 7.13531323e-05, 2.95518266e-05,\n",
              "        1.45801958e-04, 3.53674977e-05, 6.20639053e-05, 1.56755456e-05,\n",
              "        2.72584911e-05, 1.68209334e-05, 9.40307159e-05, 1.99756641e-05,\n",
              "        1.98900811e-04, 2.23230540e-04, 5.07795977e-05, 1.94212795e-04,\n",
              "        2.30806494e-04, 1.71367075e-05, 1.47213771e-05, 1.60853225e-04,\n",
              "        6.98257971e-05, 7.52397966e-05, 6.20590326e-05, 2.02510086e-04,\n",
              "        1.65774823e-05, 3.61017692e-05, 4.85737702e-05, 5.94207980e-05,\n",
              "        4.23332044e-05, 2.77796014e-05, 8.53255294e-05, 1.71339369e-04,\n",
              "        5.58177357e-05, 5.38144588e-04, 1.75953687e-04, 4.62052500e-05,\n",
              "        7.52858678e-05, 1.90267969e-04, 1.86920227e-04, 2.44352874e-05,\n",
              "        4.85507343e-05, 4.38272754e-05, 9.76364108e-06, 3.78779822e-05,\n",
              "        3.12553368e-04, 2.15436485e-05, 1.57433340e-03, 4.61969820e-05,\n",
              "        7.44079901e-05, 6.51844244e-05, 1.16903901e-05, 1.46408421e-05,\n",
              "        2.51792596e-05, 1.60328835e-04, 3.55168469e-05, 1.19463364e-04,\n",
              "        8.21905164e-05, 1.70654416e-05, 3.25780486e-04, 2.06969267e-04,\n",
              "        1.78301994e-04, 1.38632562e-05, 2.25576737e-05, 2.46877179e-04,\n",
              "        4.10218908e-04, 5.19062161e-05, 2.10466361e-04, 3.94080453e-05,\n",
              "        4.82599253e-05, 3.07857384e-05, 4.39917878e-05, 1.22097374e-04,\n",
              "        3.82459144e-04, 3.64823744e-05, 5.47866182e-05, 5.77388854e-04,\n",
              "        3.67982375e-05, 1.72912489e-05, 7.43412528e-05, 1.79996781e-03,\n",
              "        2.95141016e-05, 6.85349662e-04, 3.75545515e-05, 1.56228038e-05,\n",
              "        8.10344031e-05, 1.63190814e-04, 2.83111999e-05, 2.53152600e-04,\n",
              "        4.80365573e-05, 3.55464751e-05, 1.47962501e-05, 2.22947639e-04,\n",
              "        5.22492527e-04, 1.51531287e-04, 1.08008090e-04, 9.94123254e-05,\n",
              "        1.72318420e-05, 5.11012836e-05, 5.89565520e-05, 1.06751476e-04]),\n",
              " 'std_test_score': array([0.07345622, 0.07578746, 0.05110127, 0.07345622, 0.06153806,\n",
              "        0.05678831, 0.07345622, 0.02198871, 0.06162923, 0.07345622,\n",
              "        0.06652031, 0.07122511, 0.07345622, 0.05905101, 0.07132539,\n",
              "        0.07345622, 0.0848822 , 0.0692098 , 0.07345622, 0.06521202,\n",
              "        0.07169285, 0.07345622, 0.04825636, 0.0608986 , 0.07345622,\n",
              "        0.01823682, 0.07416527, 0.07345622, 0.02076375, 0.063836  ,\n",
              "        0.07345622, 0.06585781, 0.06480155, 0.07345622, 0.06468896,\n",
              "        0.0636425 , 0.0711635 , 0.05461724, 0.07846907, 0.07345622,\n",
              "        0.03955989, 0.07054655, 0.07345622, 0.05599853, 0.07463535,\n",
              "        0.02465305, 0.00682   , 0.020807  , 0.04867362, 0.00248998,\n",
              "        0.04432622, 0.02053975, 0.00248998, 0.0862618 , 0.02634674,\n",
              "        0.05969993, 0.05224368, 0.06010115, 0.05670825, 0.05350406,\n",
              "        0.03883137, 0.03650679, 0.0523957 , 0.03570229, 0.01941507,\n",
              "        0.05426836, 0.02370854, 0.05755144, 0.06120067, 0.02178221,\n",
              "        0.04792944, 0.06394968, 0.05320466, 0.00248998, 0.0081068 ,\n",
              "        0.04033553, 0.00192873, 0.05308476, 0.02484312, 0.00192873,\n",
              "        0.07958758, 0.01991407, 0.02783976, 0.0295669 , 0.06736546,\n",
              "        0.00296627, 0.07551938, 0.04607988, 0.01294024, 0.06758515,\n",
              "        0.05260078, 0.07233581, 0.06562324, 0.05160969, 0.04303193,\n",
              "        0.06000164, 0.03505288, 0.03370968, 0.07057616, 0.05492844,\n",
              "        0.06986772, 0.07827351, 0.02555381, 0.09712925, 0.06419724,\n",
              "        0.03674718, 0.07193866, 0.06596162, 0.04443769, 0.04950613,\n",
              "        0.06655492, 0.063475  , 0.06503776, 0.06771564, 0.07658173,\n",
              "        0.04360614, 0.0773312 , 0.04699481, 0.07885698, 0.0659341 ,\n",
              "        0.06721815, 0.0680839 , 0.06726807, 0.04500907, 0.08952373,\n",
              "        0.06927078, 0.05415541, 0.05325585, 0.06248994, 0.05265363,\n",
              "        0.04347282, 0.06431181, 0.02784049, 0.04052653, 0.08080565,\n",
              "        0.05556805, 0.07039421, 0.04932055, 0.01849589, 0.03026087,\n",
              "        0.05899518, 0.04051053, 0.05539501, 0.05847541, 0.02719717,\n",
              "        0.05302452, 0.05444646, 0.0342104 , 0.05898384, 0.05866415,\n",
              "        0.03137927, 0.06999631, 0.03146554, 0.03014774, 0.03996248,\n",
              "        0.05972796, 0.05900545, 0.05847388, 0.0411916 , 0.02629864,\n",
              "        0.03498858, 0.03073986, 0.08825881, 0.05122631, 0.05375853,\n",
              "        0.04720346, 0.01448334, 0.02628473, 0.03743138, 0.04225196,\n",
              "        0.03033165, 0.03713367, 0.08087953, 0.01681572, 0.02370986,\n",
              "        0.04168523, 0.02425752, 0.03304559, 0.05855513, 0.04027249])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbZs8Z3UY201",
        "colab_type": "text"
      },
      "source": [
        "## **Comentários:**\n",
        "Na otimização de parâmetros a random search resultou em 62% e a Grid search em 65%, resultando no melhor score até agora, embora ainda baixo. \n",
        "A utilização de parâmetros diferentes podem auxiliar na melhora do desempenho das RNA. \n",
        "Com uso da busca aleatoria (**Random Search**) o resultado **ótimo** encontrado foi de 62%, sendo a configuração eleita:\n",
        "* Método de ativação: **\"identity\"**;\n",
        "* Número de camadas ocultas: **50**, \n",
        "* Número máximo de iteraçõers **500**; e,\n",
        "* Solver: **lbfgs**\n",
        "Com uso da busca em grade (**Grid Search**) o resultado **ótimo** encontrado foi de 65%, sendo a configuração eleita:\n",
        "* Método de ativação: **relu**;\n",
        "* Número de camadas ocultas: **10**, \n",
        "* Número máximo de iteraçõers **1000**; e,\n",
        "* Solver: **lbfgs**\n",
        "\n",
        "#Observa-se, portanto, o melhor desempenho do modelo obtido **Grid Search** em que todas as instâncias são utilizadas. \n",
        "\n",
        "\n"
      ]
    }
  ]
}